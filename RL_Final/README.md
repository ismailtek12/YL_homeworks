# DQN TabanlÄ± Basit Depo Robotu SimÃ¼lasyonu

## ğŸ“Œ Projenin AmacÄ±

Bu proje, basit bir Ä±zgara tabanlÄ± depo ortamÄ±nda Ã§alÄ±ÅŸan bir robotun, takviyeli Ã¶ÄŸrenme (Reinforcement Learning) yÃ¶ntemi olan **Deep Q-Learning (DQN)** kullanÄ±larak gÃ¶revleri Ã¶ÄŸrenmesini ve gerÃ§ekleÅŸtirmesini amaÃ§lamaktadÄ±r. Robotun temel gÃ¶revleri ÅŸunlardÄ±r:

- Belirli bir noktadan yÃ¼k almak ve hedefe taÅŸÄ±mak  
- Batarya seviyesini etkin ÅŸekilde yÃ¶netmek  
- Engellerden kaÃ§Ä±nmak

---

## ğŸŒ Ortam TanÄ±mÄ±: `SimpleWarehouseEnv`

Ã–zel olarak tanÄ±mlanmÄ±ÅŸ `SimpleWarehouseEnv` sÄ±nÄ±fÄ±, `gym.Env` sÄ±nÄ±fÄ±ndan tÃ¼retilmiÅŸtir.

| Ã–zellik          | DeÄŸer |
|------------------|-------|
| Izgara boyutu    | 5x5   |
| YÃ¼k pozisyonu    | (3, 3) |
| Hedef pozisyonu  | (4, 4) |
| Åarj istasyonu   | (0, 4) |
| Engeller         | [(2, 2)] |
| Batarya kapasitesi | 50 birim |

---

## ğŸ® Aksiyon UzayÄ±

| Aksiyon Kodu | AÃ§Ä±klama      |
|--------------|---------------|
| 0            | YukarÄ± git    |
| 1            | AÅŸaÄŸÄ± git     |
| 2            | SaÄŸa git      |
| 3            | Sola git      |
| 4            | YÃ¼kÃ¼ al       |
| 5            | YÃ¼kÃ¼ bÄ±rak    |
| 6            | Åarj et       |

---

## âš™ï¸ OrtamÄ±n Dinamikleri: `step()` Fonksiyonu

- Hareket aksiyonlarÄ± bataryadan **1 birim enerji** tÃ¼ketir.
- Engellerden geÃ§iÅŸ engellenir ve **ceza puanÄ±** verilir.
- Batarya sÄ±fÄ±rlanÄ±rsa gÃ¶rev **baÅŸarÄ±sÄ±z** sayÄ±lÄ±r.
- Åarj istasyonuna ulaÅŸÄ±ldÄ±ÄŸÄ±nda batarya **tam ÅŸarj** edilir.
- Hedefe yÃ¼k bÄ±rakÄ±ldÄ±ÄŸÄ±nda **yÃ¼ksek Ã¶dÃ¼l** verilir.
- YÃ¼k taÅŸÄ±nmÄ±ÅŸ ve iÅŸlem bitmiÅŸse gÃ¶rev **baÅŸarÄ±yla tamamlanÄ±r**.

---

## ğŸ¯ Ã–dÃ¼l YapÄ±sÄ±

| Durum                                | Ã–dÃ¼l       |
|--------------------------------------|------------|
| Her adÄ±m                             | -0.05      |
| Engelle Ã§arpÄ±ÅŸma                     | -1         |
| YÃ¼k alma                             | +30        |
| YÃ¼kÃ¼ hedefte bÄ±rakma                 | +100       |
| GÃ¶revin tamamlanmasÄ±                 | +200       |
| BataryanÄ±n bitmesi                   | -200       |
| Maksimum adÄ±m sayÄ±sÄ±na ulaÅŸma       | -100       |
| Åarj istasyonuna gitme              | +5         |

---

## ğŸ§  DQN Modeli

- **GiriÅŸ vektÃ¶rÃ¼**: 7 boyutlu durum vektÃ¶rÃ¼
- **Ã‡Ä±kÄ±ÅŸ vektÃ¶rÃ¼**: 7 boyutlu aksiyon uzayÄ±

---
**Model mimarisi:**

GiriÅŸ (7) â†’ Dense(128) + ReLU â†’ Dense(64) + ReLU â†’ Ã‡Ä±kÄ±ÅŸ (7)

----

## ğŸ” Modelin Karar SÃ¼reci

1. GÃ¼ncel durum vektÃ¶rÃ¼ modele verilir.
2. Model, her aksiyon iÃ§in bir Q-deÄŸeri Ã¼retir.
3. En yÃ¼ksek Q-deÄŸerine sahip aksiyon seÃ§ilir (veya keÅŸif iÃ§in epsilon-greedy yÃ¶ntemi uygulanÄ±r).
4. SeÃ§ilen aksiyon Ã§evreye uygulanÄ±r, karÅŸÄ±lÄ±k olarak yeni durum ve Ã¶dÃ¼l alÄ±nÄ±r.
5. Bu deneyim, replay bufferâ€™a kaydedilir.
6. Rastgele seÃ§ilen mini-batch ile aÄŸ gÃ¼ncellenir.
